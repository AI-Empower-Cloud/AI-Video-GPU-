{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f74860",
   "metadata": {},
   "source": [
    "# üöÄ AI Video GPU - Google Colab Setup\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/ai-video-gpu/blob/main/cloud-gpu-setups/google-colab/ai_video_gpu_colab.ipynb)\n",
    "\n",
    "## üéØ Features Available\n",
    "- ‚úÖ AI Video Generation\n",
    "- ‚úÖ Voice Cloning\n",
    "- ‚úÖ Lip Sync Technology\n",
    "- ‚úÖ Image Processing\n",
    "- ‚úÖ Web Interface\n",
    "- ‚úÖ Cloud Storage Integration\n",
    "\n",
    "## üîß System Requirements\n",
    "- **GPU**: Tesla T4 (16GB VRAM)\n",
    "- **RAM**: 12-13GB\n",
    "- **Storage**: 107GB\n",
    "- **Time Limit**: 12 hours\n",
    "\n",
    "## ‚ö†Ô∏è Important Notes\n",
    "- Enable GPU runtime: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "- Session will reset after 12 hours\n",
    "- Save outputs to Google Drive for persistence\n",
    "- Weekly usage limits apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd7992",
   "metadata": {},
   "source": [
    "## üîß Step 1: System Setup and GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64653293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and system info\n",
    "import torch\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"üöÄ AI Video GPU - Google Colab Setup\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
    "    print(f\"üìä GPU Memory: {gpu_memory:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU available! Please enable GPU runtime.\")\n",
    "    print(\"Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "\n",
    "# System info\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"\\nüîç NVIDIA System Info:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "# Check disk space\n",
    "disk_usage = subprocess.run(['df', '-h', '/'], capture_output=True, text=True)\n",
    "print(\"\\nüíæ Disk Usage:\")\n",
    "print(disk_usage.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9bae72",
   "metadata": {},
   "source": [
    "## üíæ Step 2: Mount Google Drive (Optional but Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "try:\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úÖ Google Drive mounted successfully\")\n",
    "    \n",
    "    # Create AI Video GPU directory\n",
    "    ai_video_dir = '/content/drive/MyDrive/AI_Video_GPU'\n",
    "    os.makedirs(ai_video_dir, exist_ok=True)\n",
    "    os.makedirs(f'{ai_video_dir}/outputs', exist_ok=True)\n",
    "    os.makedirs(f'{ai_video_dir}/models', exist_ok=True)\n",
    "    \n",
    "    print(f\"üìÅ Created directories:\")\n",
    "    print(f\"   - {ai_video_dir}\")\n",
    "    print(f\"   - {ai_video_dir}/outputs\")\n",
    "    print(f\"   - {ai_video_dir}/models\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error mounting drive: {e}\")\n",
    "    print(\"Continuing without Google Drive...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a9ac5",
   "metadata": {},
   "source": [
    "## üì¶ Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a43b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "print(\"üîß Installing system dependencies...\")\n",
    "\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq ffmpeg espeak espeak-data libespeak1 libespeak-dev\n",
    "!apt-get install -y -qq portaudio19-dev python3-pyaudio\n",
    "\n",
    "print(\"‚úÖ System dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python dependencies\n",
    "print(\"üì¶ Installing Python packages...\")\n",
    "\n",
    "# Core ML libraries\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers diffusers accelerate\n",
    "!pip install -q xformers\n",
    "\n",
    "# Video and audio processing\n",
    "!pip install -q opencv-python moviepy librosa soundfile\n",
    "!pip install -q pillow numpy scipy\n",
    "\n",
    "# Text-to-speech and voice cloning\n",
    "!pip install -q TTS tortoise-tts pydub\n",
    "!pip install -q phonemizer\n",
    "\n",
    "# Face and lip sync\n",
    "!pip install -q mediapipe face-recognition\n",
    "!pip install -q opencv-contrib-python\n",
    "\n",
    "# Web interface\n",
    "!pip install -q gradio fastapi uvicorn\n",
    "!pip install -q streamlit\n",
    "\n",
    "# Utilities\n",
    "!pip install -q tqdm pyyaml click loguru\n",
    "!pip install -q requests aiohttp\n",
    "\n",
    "# Cloud storage\n",
    "!pip install -q boto3 google-cloud-storage\n",
    "\n",
    "print(\"‚úÖ Python packages installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3572f07",
   "metadata": {},
   "source": [
    "## üì• Step 4: Clone AI Video GPU Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "# Remove existing directory if it exists\n",
    "if os.path.exists('/content/AI-Video-GPU'):\n",
    "    !rm -rf /content/AI-Video-GPU\n",
    "\n",
    "# Clone repository (replace with your actual repository URL)\n",
    "!git clone https://github.com/your-username/AI-Video-GPU.git /content/AI-Video-GPU\n",
    "\n",
    "# Change to the project directory\n",
    "os.chdir('/content/AI-Video-GPU')\n",
    "\n",
    "print(\"‚úÖ Repository cloned successfully\")\n",
    "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# List project structure\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e1a07",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 5: Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b583e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment configuration for Colab\n",
    "import os\n",
    "\n",
    "# Environment variables for Colab\n",
    "env_config = \"\"\"\n",
    "# AI Video GPU Configuration for Google Colab\n",
    "ENVIRONMENT=colab\n",
    "GPU_ENABLED=true\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "# Paths (Colab specific)\n",
    "DATA_DIR=/content/data\n",
    "OUTPUT_DIR=/content/outputs\n",
    "MODEL_CACHE_DIR=/content/models\n",
    "TEMP_DIR=/tmp\n",
    "\n",
    "# Google Drive paths (if mounted)\n",
    "DRIVE_OUTPUT_DIR=/content/drive/MyDrive/AI_Video_GPU/outputs\n",
    "DRIVE_MODEL_DIR=/content/drive/MyDrive/AI_Video_GPU/models\n",
    "\n",
    "# Performance settings\n",
    "MAX_BATCH_SIZE=4\n",
    "MAX_VIDEO_LENGTH=30\n",
    "MAX_RESOLUTION=1080\n",
    "\n",
    "# Web interface\n",
    "WEB_HOST=0.0.0.0\n",
    "WEB_PORT=7860\n",
    "GRADIO_SHARE=true\n",
    "\n",
    "# Logging\n",
    "LOG_LEVEL=INFO\n",
    "LOG_FILE=/content/ai_video_gpu.log\n",
    "\"\"\"\n",
    "\n",
    "# Write configuration\n",
    "with open('.env.colab', 'w') as f:\n",
    "    f.write(env_config)\n",
    "\n",
    "# Create necessary directories\n",
    "directories = ['/content/data', '/content/outputs', '/content/models']\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"üìÅ Created: {directory}\")\n",
    "\n",
    "print(\"‚úÖ Environment configured for Google Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39693376",
   "metadata": {},
   "source": [
    "## ü§ñ Step 6: Download AI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download essential AI models\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "print(\"ü§ñ Downloading AI models...\")\n",
    "\n",
    "# Create model cache directory\n",
    "model_cache = '/content/models'\n",
    "os.environ['TRANSFORMERS_CACHE'] = model_cache\n",
    "os.environ['HF_HOME'] = model_cache\n",
    "\n",
    "try:\n",
    "    # Download text-to-speech model\n",
    "    print(\"üì• Downloading TTS model...\")\n",
    "    from TTS.api import TTS\n",
    "    tts = TTS(model_name=\"tts_models/en/ljspeech/tacotron2-DDC\")\n",
    "    print(\"‚úÖ TTS model loaded\")\n",
    "    \n",
    "    # Download basic diffusion model for images\n",
    "    print(\"üì• Downloading image generation model...\")\n",
    "    from diffusers import StableDiffusionPipeline\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        torch_dtype=torch.float16,\n",
    "        cache_dir=model_cache\n",
    "    )\n",
    "    print(\"‚úÖ Image generation model loaded\")\n",
    "    \n",
    "    # Download face detection model\n",
    "    print(\"üì• Downloading face detection model...\")\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    print(\"‚úÖ Face detection model loaded\")\n",
    "    \n",
    "    print(\"\\nüéâ All models downloaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading models: {e}\")\n",
    "    print(\"Some features may not work properly.\")\n",
    "\n",
    "# Check model cache size\n",
    "!du -sh /content/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34b2d4",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Launch Web Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e45e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Gradio web interface\n",
    "import gradio as gr\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Simple demo interface for AI Video GPU\n",
    "def generate_video_demo(prompt, duration=5):\n",
    "    \"\"\"\n",
    "    Demo function for video generation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # This is a placeholder - implement actual video generation\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"/content/outputs/demo_video_{timestamp}.mp4\"\n",
    "        \n",
    "        # For demo purposes, create a simple message\n",
    "        message = f\"Video generation requested:\\nPrompt: {prompt}\\nDuration: {duration}s\\nTimestamp: {timestamp}\"\n",
    "        \n",
    "        # Save to outputs\n",
    "        with open(f\"/content/outputs/generation_log_{timestamp}.txt\", \"w\") as f:\n",
    "            f.write(message)\n",
    "        \n",
    "        return message\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def generate_voice_demo(text, voice_type=\"female\"):\n",
    "    \"\"\"\n",
    "    Demo function for voice generation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Create a simple TTS audio (placeholder)\n",
    "        message = f\"Voice generation requested:\\nText: {text}\\nVoice: {voice_type}\\nTimestamp: {timestamp}\"\n",
    "        \n",
    "        return message\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"AI Video GPU - Colab Demo\", theme=\"soft\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üöÄ AI Video GPU - Google Colab Demo\n",
    "    \n",
    "    Welcome to AI Video GPU running on Google Colab! This is a demonstration interface.\n",
    "    \n",
    "    ## üéØ Available Features:\n",
    "    - Text-to-Video Generation\n",
    "    - Voice Cloning and TTS\n",
    "    - Image Processing\n",
    "    - Model Management\n",
    "    \n",
    "    ## ‚ö†Ô∏è Colab Limitations:\n",
    "    - 12-hour session limit\n",
    "    - Files are temporary (save to Google Drive)\n",
    "    - GPU usage quotas apply\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tab(\"Video Generation\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                video_prompt = gr.Textbox(\n",
    "                    label=\"Video Prompt\",\n",
    "                    placeholder=\"Describe the video you want to generate...\",\n",
    "                    lines=3\n",
    "                )\n",
    "                video_duration = gr.Slider(\n",
    "                    minimum=1,\n",
    "                    maximum=30,\n",
    "                    value=5,\n",
    "                    label=\"Duration (seconds)\"\n",
    "                )\n",
    "                generate_video_btn = gr.Button(\"Generate Video\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                video_output = gr.Textbox(\n",
    "                    label=\"Generation Status\",\n",
    "                    lines=10\n",
    "                )\n",
    "        \n",
    "        generate_video_btn.click(\n",
    "            generate_video_demo,\n",
    "            inputs=[video_prompt, video_duration],\n",
    "            outputs=video_output\n",
    "        )\n",
    "    \n",
    "    with gr.Tab(\"Voice Generation\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                voice_text = gr.Textbox(\n",
    "                    label=\"Text to Speech\",\n",
    "                    placeholder=\"Enter text to convert to speech...\",\n",
    "                    lines=3\n",
    "                )\n",
    "                voice_type = gr.Dropdown(\n",
    "                    choices=[\"female\", \"male\", \"child\"],\n",
    "                    value=\"female\",\n",
    "                    label=\"Voice Type\"\n",
    "                )\n",
    "                generate_voice_btn = gr.Button(\"Generate Voice\", variant=\"primary\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                voice_output = gr.Textbox(\n",
    "                    label=\"Generation Status\",\n",
    "                    lines=10\n",
    "                )\n",
    "        \n",
    "        generate_voice_btn.click(\n",
    "            generate_voice_demo,\n",
    "            inputs=[voice_text, voice_type],\n",
    "            outputs=voice_output\n",
    "        )\n",
    "    \n",
    "    with gr.Tab(\"System Info\"):\n",
    "        gr.Markdown(f\"\"\"\n",
    "        ## üñ•Ô∏è System Information\n",
    "        \n",
    "        **Platform**: Google Colab  \n",
    "        **GPU**: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}  \n",
    "        **CUDA Available**: {torch.cuda.is_available()}  \n",
    "        **Python Version**: {os.sys.version}  \n",
    "        **PyTorch Version**: {torch.__version__}  \n",
    "        \n",
    "        ## üìÅ Directory Structure\n",
    "        - `/content/AI-Video-GPU/` - Main project\n",
    "        - `/content/outputs/` - Generated content\n",
    "        - `/content/models/` - AI models cache\n",
    "        - `/content/drive/MyDrive/AI_Video_GPU/` - Google Drive storage\n",
    "        \n",
    "        ## üíæ Storage Tips\n",
    "        - Save important outputs to Google Drive\n",
    "        - Session resets after 12 hours\n",
    "        - Models will be re-downloaded each session\n",
    "        \"\"\")\n",
    "\n",
    "# Launch the interface\n",
    "print(\"üöÄ Launching AI Video GPU Web Interface...\")\n",
    "print(\"üì± The interface will be available at the public URL shown below\")\n",
    "print(\"üîó Click the public URL to access the interface\")\n",
    "\n",
    "demo.launch(\n",
    "    share=True,  # Create public URL\n",
    "    server_name=\"0.0.0.0\",\n",
    "    server_port=7860,\n",
    "    show_tips=True,\n",
    "    enable_queue=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acb0675",
   "metadata": {},
   "source": [
    "## üí° Usage Tips and Troubleshooting\n",
    "\n",
    "### üéØ Getting the Most from Colab\n",
    "1. **Save Regularly**: Copy important outputs to Google Drive\n",
    "2. **Monitor GPU Usage**: Check remaining GPU quota\n",
    "3. **Use Efficient Settings**: Lower resolution for faster processing\n",
    "4. **Keep Session Active**: Interact with the notebook regularly\n",
    "\n",
    "### üîß Common Issues\n",
    "\n",
    "**GPU Not Available**:\n",
    "- Go to Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "- Restart runtime if needed\n",
    "\n",
    "**Out of Memory**:\n",
    "- Reduce batch size\n",
    "- Lower video resolution\n",
    "- Restart runtime to clear memory\n",
    "\n",
    "**Session Timeout**:\n",
    "- Sessions reset after 12 hours\n",
    "- Re-run all cells to restart\n",
    "- Models will need to be re-downloaded\n",
    "\n",
    "### üìä Performance Optimization\n",
    "- Use FP16 precision for faster processing\n",
    "- Enable gradient checkpointing\n",
    "- Process videos in smaller chunks\n",
    "- Cache models in Google Drive\n",
    "\n",
    "### üîó Useful Commands\n",
    "```python\n",
    "# Check GPU memory\n",
    "!nvidia-smi\n",
    "\n",
    "# Monitor disk usage\n",
    "!df -h\n",
    "\n",
    "# Clear GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Save to Google Drive\n",
    "!cp /content/outputs/* /content/drive/MyDrive/AI_Video_GPU/outputs/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
