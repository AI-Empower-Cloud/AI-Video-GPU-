# SageMaker Studio Lab Setup Guide\n\n## Getting Started with Amazon SageMaker Studio Lab\n\n### Account Creation\n1. **Apply for Account**: Visit [studiolab.sagemaker.aws](https://studiolab.sagemaker.aws)\n2. **Request Access**: Fill out the application form\n3. **Wait for Approval**: Usually takes 1-3 business days\n4. **Email Verification**: Check your email and verify your account\n\n### First-Time Setup\n1. **Login**: Use your approved credentials\n2. **Create Project**: Click \"Create Project\"\n3. **Select Runtime**: Choose **GPU** (crucial for AI Video GPU platform)\n4. **Launch Environment**: Wait for the environment to initialize\n5. **Upload Notebook**: Upload the `ai_video_gpu_sagemaker.ipynb` file\n\n## Environment Specifications\n\n| Resource | Specification |\n|----------|---------------|\n| **GPU** | NVIDIA T4 (16GB VRAM) |\n| **CPU** | 4 vCPUs |\n| **RAM** | 12GB |\n| **Storage** | 15GB (persistent) |\n| **Daily Quota** | 4 hours GPU time |\n| **Session Limit** | 8 hours maximum |\n\n## Key Features\n\n### ✅ Advantages\n- **Persistent Storage**: Files survive across sessions\n- **Professional Environment**: Full JupyterLab interface\n- **Stable Performance**: Dedicated resources\n- **Longer Sessions**: 8-hour maximum vs 90 minutes in Colab\n- **No Interruptions**: More reliable than Colab\n- **Free Tier**: Completely free with daily quota\n\n### ⚠️ Limitations\n- **Account Approval**: Requires application process\n- **Daily Quota**: 4 hours/day GPU time\n- **Storage Limit**: 15GB persistent storage\n- **Single GPU**: Only one T4 GPU available\n- **No Root Access**: Limited system-level modifications\n\n## Step-by-Step Usage\n\n### 1. Launch GPU Environment\n```bash\n# In Studio Lab interface:\n# 1. Create new project\n# 2. Select \"GPU\" compute type\n# 3. Click \"Start runtime\"\n```\n\n### 2. Upload and Run Notebook\n1. Upload `ai_video_gpu_sagemaker.ipynb`\n2. Open the notebook\n3. Run cells sequentially\n4. Wait for setup completion\n\n### 3. Monitor Resources\n```python\n# Check GPU usage\n!nvidia-smi\n\n# Check disk space\n!df -h /home/studio-lab-user\n\n# Monitor memory\n!free -h\n```\n\n### 4. Save Your Work\n- Files in `/home/studio-lab-user/` persist across sessions\n- Use version control for notebooks\n- Export important outputs before quota expires\n\n## Best Practices\n\n### Resource Management\n1. **Monitor GPU Time**: Track usage in the dashboard\n2. **Stop When Idle**: Stop GPU runtime when not actively using\n3. **Clean Up Regularly**: Remove old models and outputs\n4. **Use Efficient Models**: Choose smaller variants for testing\n\n### File Organization\n```\n/home/studio-lab-user/\n├── AI-Video-GPU/          # Project code\n├── models/                # Cached models (persistent)\n├── outputs/               # Generated content\n├── backups/               # Regular backups\n└── notebooks/             # Custom notebooks\n```\n\n### Performance Optimization\n1. **Mixed Precision**: Use FP16 to save GPU memory\n2. **Gradient Checkpointing**: For large models\n3. **Batch Processing**: Group similar requests\n4. **Model Caching**: Cache frequently used models\n\n## Troubleshooting\n\n### Common Issues\n\n#### No GPU Detected\n```python\n# Check if GPU runtime is selected\nimport torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\n```\n**Solution**: Restart with GPU compute type selected\n\n#### Out of GPU Time\n```bash\n# Check remaining quota in dashboard\n```\n**Solution**: Wait for daily reset (midnight UTC)\n\n#### Storage Full\n```bash\n# Check disk usage\ndu -sh /home/studio-lab-user/*\n\n# Clean up large files\nfind /home/studio-lab-user -type f -size +1G -ls\n```\n**Solution**: Remove old models and outputs\n\n#### Package Installation Issues\n```bash\n# Use conda instead of pip when possible\nconda install -c conda-forge package_name\n\n# For pip packages\npip install --user package_name\n```\n\n### Error Recovery\n\n#### Kernel Restart\n1. **Kernel → Restart Kernel**\n2. Re-run setup cells\n3. Check GPU availability\n\n#### Environment Reset\n1. Stop current runtime\n2. Start new GPU runtime\n3. Re-upload notebook if needed\n4. Run setup from beginning\n\n## Platform Comparison\n\n| Feature | SageMaker Studio Lab | Google Colab | Kaggle |\n|---------|---------------------|--------------|--------|\n| **GPU Quota** | 4 hrs/day | ~12 hrs/day | 30 hrs/week |\n| **Session Length** | 8 hours | 90 minutes | 9 hours |\n| **Storage** | 15GB persistent | Temporary | 20GB temporary |\n| **GPU Type** | T4 x1 | T4/V100/A100 | T4 x2/P100 |\n| **Account** | Approval required | Instant | Instant |\n| **Reliability** | High | Medium | High |\n| **Features** | Professional | Consumer | Data Science |\n\n## Advanced Usage\n\n### Custom Environments\n```bash\n# Create conda environment\nconda create -n ai-video python=3.9\nconda activate ai-video\n\n# Install packages\nconda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n```\n\n### Git Integration\n```bash\n# Configure git\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n\n# Clone private repositories (with token)\ngit clone https://token@github.com/user/private-repo.git\n```\n\n### Model Optimization\n```python\n# Enable mixed precision\nfrom torch.cuda.amp import autocast, GradScaler\n\n# Use torch.compile for faster inference (PyTorch 2.0+)\nmodel = torch.compile(model)\n\n# Optimize for inference\nmodel.eval()\nwith torch.no_grad():\n    # Your inference code\n```\n\n## Support and Resources\n\n- **Documentation**: [SageMaker Studio Lab Docs](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-lab.html)\n- **Community**: [AWS ML Community](https://aws.amazon.com/machine-learning/community/)\n- **Tutorials**: [Studio Lab Examples](https://github.com/aws/studio-lab-examples)\n- **Support**: [AWS Support](https://aws.amazon.com/support/)\n\n## Quick Start Checklist\n\n- [ ] Applied for SageMaker Studio Lab account\n- [ ] Received approval email\n- [ ] Created first project with GPU runtime\n- [ ] Uploaded `ai_video_gpu_sagemaker.ipynb`\n- [ ] Ran setup cells successfully\n- [ ] Verified GPU detection\n- [ ] Tested basic functionality\n- [ ] Set up file organization\n- [ ] Configured git (optional)\n- [ ] Created backup strategy\n\n---\n\n**Note**: SageMaker Studio Lab is ideal for users who need persistent storage and professional development environment. The approval process and daily quota make it less suitable for immediate testing but excellent for serious development work.\n
