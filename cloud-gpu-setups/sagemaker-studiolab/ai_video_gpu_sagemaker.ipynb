{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b59ed5",
   "metadata": {},
   "source": [
    "# AI Video GPU Platform - SageMaker Studio Lab Setup\n",
    "\n",
    "This notebook sets up the AI Video GPU platform on Amazon SageMaker Studio Lab with free GPU access.\n",
    "\n",
    "## Prerequisites\n",
    "- SageMaker Studio Lab account (free, but requires application approval)\n",
    "- Email verification\n",
    "- GPU runtime selected\n",
    "\n",
    "## GPU Availability\n",
    "- **Free Tier**: Up to 4 hours/day of GPU time\n",
    "- **GPU Types**: T4 (single GPU)\n",
    "- **RAM**: 12GB\n",
    "- **Storage**: 15GB persistent\n",
    "- **CPU**: 4 vCPUs\n",
    "\n",
    "‚ö†Ô∏è **Important**: Make sure to select GPU runtime when starting your project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391d09a",
   "metadata": {},
   "source": [
    "## Step 1: System Information & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "print(\"üîç System Information:\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    # Check GPU utilization\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU not detected!\")\n",
    "    print(\"Make sure you're using a GPU runtime:\")\n",
    "    print(\"1. Go to File ‚Üí New ‚Üí Project\")\n",
    "    print(\"2. Select 'GPU' as the compute type\")\n",
    "    print(\"3. Or restart with GPU runtime\")\n",
    "\n",
    "# Check available disk space\n",
    "result = subprocess.run(['df', '-h', '/home/studio-lab-user'], capture_output=True, text=True)\n",
    "print(f\"\\nüíæ Disk space:\\n{result.stdout}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c42c7e",
   "metadata": {},
   "source": [
    "## Step 2: Install System Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system packages (SageMaker Studio Lab has conda preinstalled)\n",
    "!conda install -y -c conda-forge ffmpeg\n",
    "\n",
    "# Install additional system packages if needed\n",
    "!pip install --upgrade pip\n",
    "\n",
    "print(\"‚úÖ System dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e440fd8b",
   "metadata": {},
   "source": [
    "## Step 3: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de73d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change to home directory\n",
    "os.chdir('/home/studio-lab-user')\n",
    "\n",
    "# Clone the repository\n",
    "if not os.path.exists('AI-Video-GPU'):\n",
    "    !git clone https://github.com/yourusername/AI-Video-GPU.git\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"üìÅ Repository already exists\")\n",
    "    # Update existing repository\n",
    "    os.chdir('AI-Video-GPU')\n",
    "    !git pull origin main\n",
    "    os.chdir('..')\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir('/home/studio-lab-user/AI-Video-GPU')\n",
    "print(f\"üìç Current directory: {os.getcwd()}\")\n",
    "\n",
    "# List contents to verify\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9f922",
   "metadata": {},
   "source": [
    "## Step 4: Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install main requirements\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install additional packages for SageMaker Studio Lab\n",
    "!pip install gradio ipywidgets\n",
    "\n",
    "# Enable widget extensions for Jupyter\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "\n",
    "print(\"‚úÖ Python dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9c909",
   "metadata": {},
   "source": [
    "## Step 5: Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff675e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for SageMaker Studio Lab\n",
    "os.environ['SAGEMAKER_ENV'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Single GPU\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
    "\n",
    "# Set paths (using persistent storage)\n",
    "os.environ['PROJECT_ROOT'] = '/home/studio-lab-user/AI-Video-GPU'\n",
    "os.environ['MODEL_CACHE'] = '/home/studio-lab-user/models'\n",
    "os.environ['OUTPUT_DIR'] = '/home/studio-lab-user/outputs'\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('/home/studio-lab-user/models', exist_ok=True)\n",
    "os.makedirs('/home/studio-lab-user/outputs', exist_ok=True)\n",
    "os.makedirs('/home/studio-lab-user/temp', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Environment configured for SageMaker Studio Lab!\")\n",
    "print(f\"üìÅ Models cache: {os.environ['MODEL_CACHE']}\")\n",
    "print(f\"üìÅ Output directory: {os.environ['OUTPUT_DIR']}\")\n",
    "print(\"üíæ Note: Files are persistent across sessions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b6484",
   "metadata": {},
   "source": [
    "## Step 6: Download Models (Optional - Heavy Downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell downloads AI models. Uncomment and run if needed.\n",
    "# Note: Models are large and may take significant time\n",
    "# Advantage: Models persist across sessions in SageMaker Studio Lab\n",
    "\n",
    "# import torch\n",
    "# from huggingface_hub import snapshot_download\n",
    "# import os\n",
    "# \n",
    "# model_cache = '/home/studio-lab-user/models'\n",
    "# \n",
    "# print(\"üîÑ Downloading models... This may take several minutes\")\n",
    "# print(\"üíæ Models will be cached and persist across sessions\")\n",
    "# \n",
    "# # Download Stable Diffusion model\n",
    "# try:\n",
    "#     model_path = snapshot_download(\n",
    "#         repo_id=\"runwayml/stable-diffusion-v1-5\",\n",
    "#         cache_dir=model_cache,\n",
    "#         allow_patterns=[\"*.bin\", \"*.json\", \"*.txt\"]\n",
    "#     )\n",
    "#     print(f\"‚úÖ Stable Diffusion downloaded to {model_path}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Error downloading Stable Diffusion: {e}\")\n",
    "# \n",
    "# # Check disk usage after download\n",
    "# !df -h /home/studio-lab-user\n",
    "\n",
    "print(\"üí° Model download cell ready. Uncomment code above to download models.\")\n",
    "print(\"‚úÖ Advantage: Models persist across sessions in Studio Lab!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904d328",
   "metadata": {},
   "source": [
    "## Step 7: Launch the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f290ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project to Python path\n",
    "sys.path.append('/home/studio-lab-user/AI-Video-GPU')\n",
    "\n",
    "try:\n",
    "    # Import and launch the main application\n",
    "    from main import create_gradio_interface\n",
    "    \n",
    "    # Create the Gradio interface\n",
    "    demo = create_gradio_interface()\n",
    "    \n",
    "    # Launch with SageMaker Studio Lab specific settings\n",
    "    demo.launch(\n",
    "        share=True,  # Creates public link\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860,\n",
    "        debug=True,\n",
    "        show_error=True\n",
    "    )\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Running basic demo instead...\")\n",
    "    \n",
    "    # Fallback: Basic Gradio demo\n",
    "    import gradio as gr\n",
    "    \n",
    "    def basic_demo(text):\n",
    "        gpu_info = \"\"\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_info = f\"GPU: {torch.cuda.get_device_name(0)}\"\n",
    "        return f\"AI Video GPU Platform is running on SageMaker Studio Lab! {gpu_info}\\nInput: {text}\"\n",
    "    \n",
    "    def gpu_test():\n",
    "        if torch.cuda.is_available():\n",
    "            # Simple GPU test\n",
    "            device = torch.device('cuda')\n",
    "            x = torch.randn(1000, 1000, device=device)\n",
    "            y = torch.randn(1000, 1000, device=device)\n",
    "            z = torch.matmul(x, y)\n",
    "            return f\"‚úÖ GPU test passed! Result shape: {z.shape}\"\n",
    "        else:\n",
    "            return \"‚ùå No GPU available\"\n",
    "    \n",
    "    with gr.Blocks(title=\"AI Video GPU - SageMaker Studio Lab\") as demo:\n",
    "        gr.Markdown(\"# AI Video GPU Platform - SageMaker Studio Lab Demo\")\n",
    "        gr.Markdown(\"Basic demo running on SageMaker Studio Lab GPU environment\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                text_input = gr.Textbox(label=\"Test Input\", placeholder=\"Enter test text...\")\n",
    "                test_btn = gr.Button(\"Test Platform\")\n",
    "                gpu_test_btn = gr.Button(\"Test GPU\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                output = gr.Textbox(label=\"Output\")\n",
    "                gpu_output = gr.Textbox(label=\"GPU Test Result\")\n",
    "        \n",
    "        test_btn.click(basic_demo, inputs=text_input, outputs=output)\n",
    "        gpu_test_btn.click(gpu_test, outputs=gpu_output)\n",
    "    \n",
    "    demo.launch(\n",
    "        share=True,\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7860\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a32bf4",
   "metadata": {},
   "source": [
    "## Step 8: Monitor Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cafeee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "def monitor_resources():\n",
    "    print(\"üìä Resource Monitoring:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CPU and Memory\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    memory = psutil.virtual_memory()\n",
    "    print(f\"CPU Usage: {cpu_percent}%\")\n",
    "    print(f\"Memory Usage: {memory.percent}% ({memory.used / 1024**3:.2f} GB / {memory.total / 1024**3:.2f} GB)\")\n",
    "    \n",
    "    # Disk usage\n",
    "    disk = psutil.disk_usage('/home/studio-lab-user')\n",
    "    print(f\"Disk Usage: {disk.used / 1024**3:.2f} GB / {disk.total / 1024**3:.2f} GB ({disk.used / disk.total * 100:.1f}%)\")\n",
    "    \n",
    "    # GPU info\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"\\nüéÆ GPU Status:\")\n",
    "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated()/1024**3:.2f} GB\")\n",
    "        print(f\"GPU Memory Cached: {torch.cuda.memory_reserved()/1024**3:.2f} GB\")\n",
    "        \n",
    "        # GPU utilization\n",
    "        !nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader,nounits\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Run monitoring\n",
    "monitor_resources()\n",
    "\n",
    "# Set up periodic monitoring (optional)\n",
    "print(\"\\nüí° Run this cell periodically to monitor resource usage\")\n",
    "print(\"‚ö†Ô∏è Remember: You have 4 hours/day of GPU time in Studio Lab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f831eb0",
   "metadata": {},
   "source": [
    "## Step 9: Save and Manage Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22581d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "def create_backup():\n",
    "    \"\"\"Create a backup of important files\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    backup_dir = f\"/home/studio-lab-user/backups/backup_{timestamp}\"\n",
    "    \n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    \n",
    "    # Backup outputs\n",
    "    if os.path.exists('/home/studio-lab-user/outputs'):\n",
    "        shutil.copytree('/home/studio-lab-user/outputs', f\"{backup_dir}/outputs\")\n",
    "        print(f\"‚úÖ Outputs backed up to {backup_dir}/outputs\")\n",
    "    \n",
    "    # Backup any custom configs\n",
    "    config_files = ['config.json', 'settings.yaml', '.env']\n",
    "    for config_file in config_files:\n",
    "        if os.path.exists(f'/home/studio-lab-user/AI-Video-GPU/{config_file}'):\n",
    "            shutil.copy2(f'/home/studio-lab-user/AI-Video-GPU/{config_file}', backup_dir)\n",
    "            print(f\"‚úÖ {config_file} backed up\")\n",
    "    \n",
    "    return backup_dir\n",
    "\n",
    "def list_files():\n",
    "    \"\"\"List important files and their sizes\"\"\"\n",
    "    print(\"üìÅ File Management:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # List outputs\n",
    "    if os.path.exists('/home/studio-lab-user/outputs'):\n",
    "        print(\"\\nüì§ Output Files:\")\n",
    "        for root, dirs, files in os.walk('/home/studio-lab-user/outputs'):\n",
    "            for file in files:\n",
    "                filepath = os.path.join(root, file)\n",
    "                size = os.path.getsize(filepath) / 1024**2  # MB\n",
    "                print(f\"  {file}: {size:.2f} MB\")\n",
    "    \n",
    "    # List models\n",
    "    if os.path.exists('/home/studio-lab-user/models'):\n",
    "        print(\"\\nü§ñ Cached Models:\")\n",
    "        for root, dirs, files in os.walk('/home/studio-lab-user/models'):\n",
    "            for file in files:\n",
    "                if file.endswith(('.bin', '.pt', '.pth', '.safetensors')):\n",
    "                    filepath = os.path.join(root, file)\n",
    "                    size = os.path.getsize(filepath) / 1024**3  # GB\n",
    "                    print(f\"  {file}: {size:.2f} GB\")\n",
    "\n",
    "# Run file management functions\n",
    "list_files()\n",
    "\n",
    "print(\"\\nüí° Use create_backup() to backup your work\")\n",
    "print(\"üíæ Files in /home/studio-lab-user persist across sessions\")\n",
    "\n",
    "# Uncomment to create backup\n",
    "# backup_path = create_backup()\n",
    "# print(f\"Backup created at: {backup_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14263e61",
   "metadata": {},
   "source": [
    "## Usage Tips for SageMaker Studio Lab\n",
    "\n",
    "### üìù Important Notes:\n",
    "1. **GPU Quota**: 4 hours/day of free GPU time\n",
    "2. **Persistent Storage**: 15GB that persists across sessions\n",
    "3. **Session Management**: Sessions can run for up to 8 hours\n",
    "4. **Account**: Requires approval (may take 1-3 days)\n",
    "\n",
    "### üí° Best Practices:\n",
    "- Save frequently - your work persists!\n",
    "- Monitor GPU time usage carefully\n",
    "- Use conda environments for package management\n",
    "- Cache models in persistent storage\n",
    "- Stop GPU sessions when not in use\n",
    "\n",
    "### üîß Troubleshooting:\n",
    "- **No GPU**: Make sure you selected GPU runtime when creating project\n",
    "- **Out of GPU Time**: Wait until next day for quota reset\n",
    "- **Out of Storage**: Clean up old models and outputs\n",
    "- **Package Issues**: Use conda instead of pip when possible\n",
    "\n",
    "### üìä Resource Management:\n",
    "```python\n",
    "# Check GPU time remaining\n",
    "# (View in Studio Lab dashboard)\n",
    "\n",
    "# Monitor disk usage\n",
    "!df -h /home/studio-lab-user\n",
    "\n",
    "# Clean up models\n",
    "!du -sh /home/studio-lab-user/models/*\n",
    "\n",
    "# Check GPU status\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "### üöÄ Performance Tips:\n",
    "- Use mixed precision training (fp16)\n",
    "- Enable gradient checkpointing for large models\n",
    "- Batch smaller requests together\n",
    "- Cache frequently used models\n",
    "- Use smaller model variants for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c771e69",
   "metadata": {},
   "source": [
    "## üéâ Setup Complete!\n",
    "\n",
    "Your AI Video GPU platform is now running on SageMaker Studio Lab!\n",
    "\n",
    "### Key Advantages:\n",
    "- ‚úÖ **Persistent Storage**: Your models and outputs are saved\n",
    "- ‚úÖ **Professional Environment**: Full Jupyter Lab interface\n",
    "- ‚úÖ **Stable Performance**: Dedicated T4 GPU\n",
    "- ‚úÖ **No Time Limits**: 8-hour sessions (vs 90 min in Colab)\n",
    "\n",
    "### Next Steps:\n",
    "1. Access the Gradio interface above\n",
    "2. Upload your media files\n",
    "3. Configure generation settings\n",
    "4. Generate AI videos and content\n",
    "5. Your work will be saved automatically!\n",
    "\n",
    "### Resource Management:\n",
    "- Monitor GPU time in the Studio Lab dashboard\n",
    "- Clean up old files to manage the 15GB storage limit\n",
    "- Stop GPU sessions when not actively using them\n",
    "\n",
    "Happy creating! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
